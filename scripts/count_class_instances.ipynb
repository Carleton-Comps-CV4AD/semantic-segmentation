{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "  0: \"Roads\",\n",
    "  1: \"SideWalks\",\n",
    "  2: \"Building\",\n",
    "  3: \"Wall\",\n",
    "  4: \"Fence\",\n",
    "  5: \"Pole\",\n",
    "  6: \"TrafficLight\",\n",
    "  7: \"TrafficSign\",\n",
    "  8: \"Vegetation\",\n",
    "  9: \"Terrain\",\n",
    "  10: \"Sky\",\n",
    "  11: \"Pedestrian\",\n",
    "  12: \"Rider\",\n",
    "  13: \"Car\",\n",
    "  14: \"Truck\",\n",
    "  15: \"Bus\",\n",
    "  16: \"Train\",\n",
    "  17: \"Motorcycle\",\n",
    "  18: \"Bicycle\",\n",
    "  19: \"Static\",\n",
    "  20: \"Dynamic\",\n",
    "  21: \"Other\",\n",
    "  22: \"Water\",\n",
    "  23: \"RoadLine\",\n",
    "  24: \"Ground\",\n",
    "  25: \"Bridge\",\n",
    "  26: \"RailTrack\",\n",
    "  27: \"GuardRail\",\n",
    "  28: \"Unlabeled\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SideWalks', 1000),\n",
       " ('Building', 1000),\n",
       " ('Wall', 1000),\n",
       " ('TrafficLight', 1000),\n",
       " ('Ground', 999),\n",
       " ('Dynamic', 993),\n",
       " ('Water', 987),\n",
       " ('Pedestrian', 986),\n",
       " ('Other', 985),\n",
       " ('Vegetation', 981),\n",
       " ('Terrain', 974),\n",
       " ('Rider', 929),\n",
       " ('Truck', 900),\n",
       " ('TrafficSign', 807),\n",
       " ('Bus', 805),\n",
       " ('Sky', 741),\n",
       " ('Bridge', 689),\n",
       " ('Bicycle', 500),\n",
       " ('Car', 462),\n",
       " ('Static', 401),\n",
       " ('Pole', 366),\n",
       " ('Fence', 292),\n",
       " ('RoadLine', 280),\n",
       " ('Roads', 185),\n",
       " ('Train', 74),\n",
       " ('GuardRail', 57),\n",
       " ('Motorcycle', 0),\n",
       " ('RailTrack', 0),\n",
       " ('Unlabeled', 0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/home/zhaob/Desktop/semantic-segmentation-pytorch/1_17_rainy_day'\n",
    "seg_dir = os.path.join(data_dir, '_outSeg')\n",
    "odgt_file = os.path.join(data_dir, 'odgt', 'train.odgt')\n",
    "class_count = {label: 0 for label in class_labels.values()}\n",
    "\n",
    "train_images = []\n",
    "with open(odgt_file) as f:\n",
    "  for line in f:\n",
    "    match = re.search(r'\"_(.*?)\\.png\"', line)\n",
    "    if match:\n",
    "      value = match.group(1).split(\"/\")[-1]\n",
    "      train_images.append(value)\n",
    "    else:\n",
    "      raise ValueError('No match')\n",
    "    \n",
    "for file in os.listdir(seg_dir):\n",
    "  if file.split('.')[0] not in train_images:\n",
    "    continue\n",
    "  file = Image.open(os.path.join(seg_dir, file))\n",
    "  image_array = np.unique(np.array(file)[:,:,0].flatten())\n",
    "  for i in image_array:\n",
    "    class_count[class_labels[i]] += 1\n",
    "\n",
    "sorted(class_count.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv4ad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
