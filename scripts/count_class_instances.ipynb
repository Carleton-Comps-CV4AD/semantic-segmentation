{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "  0: \"Unlabeled\",\n",
    "  1: \"Roads\",\n",
    "  2: \"SideWalks\",\n",
    "  3: \"Building\",\n",
    "  4: \"Wall\",\n",
    "  5: \"Fence\",\n",
    "  6: \"Pole\",\n",
    "  7: \"TrafficLight\",\n",
    "  8: \"TrafficSign\",\n",
    "  9: \"Vegetation\",\n",
    "  10: \"Terrain\",\n",
    "  11: \"Sky\",\n",
    "  12: \"Pedestrian\",\n",
    "  13: \"Rider\",\n",
    "  14: \"Car\",\n",
    "  15: \"Truck\",\n",
    "  16: \"Bus\",\n",
    "  17: \"Train\",\n",
    "  18: \"Motorcycle\",\n",
    "  19: \"Bicycle\",\n",
    "  20: \"Static\",\n",
    "  21: \"Dynamic\",\n",
    "  22: \"Other\",\n",
    "  23: \"Water\",\n",
    "  24: \"RoadLine\",\n",
    "  25: \"Ground\",\n",
    "  26: \"Bridge\",\n",
    "  27: \"RailTrack\",\n",
    "  28: \"GuardRail\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Data/1_17_rainy_day'\n",
    "seg_dir = os.path.join(data_dir, '_outSeg')\n",
    "odgt_file = os.path.join(data_dir, 'odgt', 'train.odgt')\n",
    "class_count = {label: 0 for label in class_labels.values()}\n",
    "\n",
    "train_images = []\n",
    "with open(odgt_file) as f:\n",
    "  for line in f:\n",
    "    match = re.search(r'\"_(.*?)\\.png\"', line)\n",
    "    if match:\n",
    "      value = match.group(1).split(\"/\")[-1]\n",
    "      train_images.append(value)\n",
    "    else:\n",
    "      raise ValueError('No match')\n",
    "    \n",
    "for file in os.listdir(seg_dir):\n",
    "  if file.split('.')[0] not in train_images:\n",
    "    continue\n",
    "  file = Image.open(os.path.join(seg_dir, file))\n",
    "  image_array = np.unique(np.array(file)[:,:,0].flatten())\n",
    "  for i in image_array:\n",
    "    class_count[class_labels[i]] += 1\n",
    "\n",
    "sorted(class_count.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.io import loadmat\n",
    "# import scipy.io as sio\n",
    "\n",
    "# # Load the .mat file\n",
    "# mat_data = loadmat('semantic-segmentation-pytorch/data/color_29.mat')\n",
    "\n",
    "# # Inspect the keys (variables in the .mat file)\n",
    "# keys = mat_data.keys()\n",
    "# print(mat_data.keys())\n",
    "\n",
    "# # Extract the color map\n",
    "# color_map = mat_data['colors']\n",
    "# # print(color_map)\n",
    "\n",
    "# print(mat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv4ad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
