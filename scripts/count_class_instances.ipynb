{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "  0: \"Unlabeled\",\n",
    "  1: \"Roads\",\n",
    "  2: \"SideWalks\",\n",
    "  3: \"Building\",\n",
    "  4: \"Wall\",\n",
    "  5: \"Fence\",\n",
    "  6: \"Pole\",\n",
    "  7: \"TrafficLight\",\n",
    "  8: \"TrafficSign\",\n",
    "  9: \"Vegetation\",\n",
    "  10: \"Terrain\",\n",
    "  11: \"Sky\",\n",
    "  12: \"Pedestrian\",\n",
    "  13: \"Rider\",\n",
    "  14: \"Car\",\n",
    "  15: \"Truck\",\n",
    "  16: \"Bus\",\n",
    "  17: \"Train\",\n",
    "  18: \"Motorcycle\",\n",
    "  19: \"Bicycle\",\n",
    "  20: \"Static\",\n",
    "  21: \"Dynamic\",\n",
    "  22: \"Other\",\n",
    "  23: \"Water\",\n",
    "  24: \"RoadLine\",\n",
    "  25: \"Ground\",\n",
    "  26: \"Bridge\",\n",
    "  27: \"RailTrack\",\n",
    "  28: \"GuardRail\"\n",
    "}\n",
    "\n",
    "seg_dir = '/Data/toledod/collectedData/walkerPath_1-6-25/_outSeg'\n",
    "class_count = {label: 0 for label in class_labels.values()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(seg_dir):\n",
    "  file = Image.open(os.path.join(seg_dir, file))\n",
    "  image_array = np.unique(np.array(file)[:,:,0].flatten())\n",
    "  for i in image_array:\n",
    "    class_count[class_labels[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unlabeled': 94,\n",
       " 'Roads': 505,\n",
       " 'SideWalks': 505,\n",
       " 'Building': 505,\n",
       " 'Wall': 158,\n",
       " 'Fence': 199,\n",
       " 'Pole': 505,\n",
       " 'TrafficLight': 423,\n",
       " 'TrafficSign': 500,\n",
       " 'Vegetation': 490,\n",
       " 'Terrain': 316,\n",
       " 'Sky': 504,\n",
       " 'Pedestrian': 414,\n",
       " 'Rider': 0,\n",
       " 'Car': 505,\n",
       " 'Truck': 62,\n",
       " 'Bus': 0,\n",
       " 'Train': 0,\n",
       " 'Motorcycle': 144,\n",
       " 'Bicycle': 72,\n",
       " 'Static': 505,\n",
       " 'Dynamic': 502,\n",
       " 'Other': 500,\n",
       " 'Water': 169,\n",
       " 'RoadLine': 504,\n",
       " 'Ground': 376,\n",
       " 'Bridge': 0,\n",
       " 'RailTrack': 36,\n",
       " 'GuardRail': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_dir2 = '/Data/toledod/collectedData/trafficPath-fall/_outSeg'\n",
    "class_count2 = {label: 0 for label in class_labels.values()}\n",
    "for file in os.listdir(seg_dir2):\n",
    "  file = Image.open(os.path.join(seg_dir2, file))\n",
    "  image_array = np.unique(np.array(file)[:,:,0].flatten())\n",
    "  for i in image_array:\n",
    "    class_count2[class_labels[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unlabeled': 33,\n",
       " 'Roads': 504,\n",
       " 'SideWalks': 504,\n",
       " 'Building': 504,\n",
       " 'Wall': 139,\n",
       " 'Fence': 163,\n",
       " 'Pole': 504,\n",
       " 'TrafficLight': 435,\n",
       " 'TrafficSign': 497,\n",
       " 'Vegetation': 493,\n",
       " 'Terrain': 335,\n",
       " 'Sky': 502,\n",
       " 'Pedestrian': 0,\n",
       " 'Rider': 0,\n",
       " 'Car': 504,\n",
       " 'Truck': 70,\n",
       " 'Bus': 0,\n",
       " 'Train': 0,\n",
       " 'Motorcycle': 176,\n",
       " 'Bicycle': 57,\n",
       " 'Static': 504,\n",
       " 'Dynamic': 504,\n",
       " 'Other': 498,\n",
       " 'Water': 131,\n",
       " 'RoadLine': 504,\n",
       " 'Ground': 342,\n",
       " 'Bridge': 0,\n",
       " 'RailTrack': 30,\n",
       " 'GuardRail': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.io import loadmat\n",
    "# import scipy.io as sio\n",
    "\n",
    "# # Load the .mat file\n",
    "# mat_data = loadmat('semantic-segmentation-pytorch/data/color_29.mat')\n",
    "\n",
    "# # Inspect the keys (variables in the .mat file)\n",
    "# keys = mat_data.keys()\n",
    "# print(mat_data.keys())\n",
    "\n",
    "# # Extract the color map\n",
    "# color_map = mat_data['colors']\n",
    "# # print(color_map)\n",
    "\n",
    "# print(mat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
