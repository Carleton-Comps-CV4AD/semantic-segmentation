{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_test_split(files_per_weather, train_percent=0.8, validation_percent=0.1, test_percent=0.1):\n",
    "    \"\"\"Splits the dataset into train, validation, and test sets for each weather condition.\"\"\"\n",
    "    assert train_percent + validation_percent + test_percent == 1.0, \"Splits must sum to 1.\"\n",
    "\n",
    "    train_files, validation_files, test_files = {}, {}, {}\n",
    "\n",
    "    for weather, files in files_per_weather.items():\n",
    "        num_files = len(files)\n",
    "        shuffled_files = np.random.permutation(files)  # Random shuffle\n",
    "\n",
    "        if weather == \"_outRaw\":\n",
    "            train_files[weather] = shuffled_files[:1000]  # Limit to 1000\n",
    "            validation_files[weather] = shuffled_files[1000:1125]  # 125 validation\n",
    "            test_files[weather] = shuffled_files[1125:1250]  # 125 test\n",
    "        else:\n",
    "            train_files[weather] = shuffled_files[:100]  # 100 train\n",
    "            validation_files[weather] = shuffled_files[100:112]  # 12 validation\n",
    "            test_files[weather] = shuffled_files[112:124]  # 12 test\n",
    "\n",
    "    return train_files, validation_files, test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set sizes: {'_outRaw': 1000, '_outRaw_foggy': 100}\n",
      "Validation set sizes: {'_outRaw': 125, '_outRaw_foggy': 12}\n",
      "Test set sizes: {'_outRaw': 125, '_outRaw_foggy': 12}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'odgt_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest set sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39m{w:\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(test[w])\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mw\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mtest}\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Create ODGT\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[43mmake_odgt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_folders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_folders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43modgt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLines in train.odgt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39m_\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124modgt/train.odgt\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39mencoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLines in validate.odgt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39m_\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124modgt/validate.odgt\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39mencoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 37\u001b[0m, in \u001b[0;36mmake_odgt\u001b[0;34m(raw_folders, seg_folders, train_files, validate_files, test_files, output_dir)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 odgt_line \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps({\n\u001b[1;32m     27\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfpath_img\u001b[39m\u001b[38;5;124m\"\u001b[39m: raw_path,\n\u001b[1;32m     28\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfpath_segm\u001b[39m\u001b[38;5;124m\"\u001b[39m: ann_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweather\u001b[39m\u001b[38;5;124m\"\u001b[39m: weather  \u001b[38;5;66;03m# Store weather condition\u001b[39;00m\n\u001b[1;32m     32\u001b[0m                 })\n\u001b[1;32m     35\u001b[0m                 odgt_file\u001b[38;5;241m.\u001b[39mwrite(odgt_line \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43modgt_files\u001b[49m\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m     38\u001b[0m     f\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'odgt_files' is not defined"
     ]
    }
   ],
   "source": [
    "def make_odgt(raw_folders, seg_folders, train_files, validate_files, test_files, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    datasets = {\n",
    "        'train': train_files,\n",
    "        'validate': validate_files,\n",
    "        'test': test_files\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for key, file_dict in datasets.items():\n",
    "        with open(os.path.join(output_dir, f'{key}.odgt'), 'w', encoding='utf-8') as odgt_file:\n",
    "            for weather, files in file_dict.items():  # Iterate over each weather condition\n",
    "                for raw in files:\n",
    "                    raw_path = os.path.abspath(os.path.join(raw_folders[weather], raw))\n",
    "                    ann_path = os.path.abspath(os.path.join(seg_folders[weather], raw))\n",
    "\n",
    "                    if not os.path.exists(raw_path) or not os.path.exists(ann_path):\n",
    "                        print(f\"Skipping missing file: {raw}\")\n",
    "                        continue\n",
    "\n",
    "                    raw_img = Image.open(raw_path)\n",
    "                    ann_img = Image.open(ann_path)\n",
    "                    assert raw_img.size == ann_img.size, f\"Size mismatch for {raw} in {weather}\"\n",
    "\n",
    "                    odgt_line = json.dumps({\n",
    "                        \"fpath_img\": raw_path,\n",
    "                        \"fpath_segm\": ann_path,\n",
    "                        \"width\": raw_img.width,\n",
    "                        \"height\": raw_img.height,\n",
    "                        \"weather\": weather  # Store weather condition\n",
    "                    })\n",
    "\n",
    "                    \n",
    "                    odgt_file.write(odgt_line + '\\n')\n",
    "\n",
    "    for f in odgt_files.values():\n",
    "        f.close()\n",
    "\n",
    "# Define paths\n",
    "data_root_dir = '/home/zhaob/Desktop/semantic-segmentation-pytorch/1_17_clear_day_mixed'\n",
    "# weather_conditions = [\"_outRaw\", \"_outRaw_foggy\", \"_outRaw_night\"]\n",
    "weather_conditions = [\"_outRaw\", \"_outRaw_foggy\"]\n",
    "raw_folders = {w: os.path.join(data_root_dir, w) for w in weather_conditions}\n",
    "seg_folders = {w: os.path.join(data_root_dir, w.replace(\"_outRaw\", \"_outSeg\")) for w in weather_conditions}\n",
    "\n",
    "# Collect only valid image files\n",
    "files_per_weather = {\n",
    "    w: sorted([f for f in os.listdir(raw_folders[w]) if f.endswith('.png')])\n",
    "    for w in weather_conditions\n",
    "}\n",
    "\n",
    "# Perform dataset split\n",
    "train, validate, test = train_validation_test_split(files_per_weather)\n",
    "\n",
    "print(f\"Train set sizes: { {w: len(train[w]) for w in train} }\")\n",
    "print(f\"Validation set sizes: { {w: len(validate[w]) for w in validate} }\")\n",
    "print(f\"Test set sizes: { {w: len(test[w]) for w in test} }\")\n",
    "\n",
    "# Create ODGT\n",
    "make_odgt(raw_folders, seg_folders, train, validate, test, 'odgt')\n",
    "\n",
    "print(f\"Lines in train.odgt: {sum(1 for _ in open('odgt/train.odgt', 'r', encoding='utf-8'))}\")\n",
    "print(f\"Lines in validate.odgt: {sum(1 for _ in open('odgt/validate.odgt', 'r', encoding='utf-8'))}\")\n",
    "print(f\"Lines in test.odgt: {sum(1 for _ in open('odgt/test.odgt', 'r', encoding='utf-8'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv4ad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
